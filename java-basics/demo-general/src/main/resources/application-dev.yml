server:
  port: 8080
  servlet:
    context-path: /demo
    encoding:
      force: true   # true = 使用当前配置文件进行编码, 可配合 charset: utf-8 使用

# Spring 配置
spring:
  application:
    name: demo
  main:
    allow-bean-definition-overriding: true # true = 允许后覆盖相同名称的 bean, 防止项目集成后出现重复定义的冲突

  data:
    web:
      pageable:
        one-indexed-parameters: true  # true = 分页查询页码从 1 而不是 0 开始

  # 数据库
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/data?createDatabaseIfNotExist=true&useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true&allowPublicKeyRetrieval=true
    username: root
    password: "xaTqi5!moNzx#noZcYr"
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 3
      maximum-pool-size: 10
    druid:
      test-while-idle: true
      validation-query: SELECT 1

  # 邮件发送
  mail:
    host: smtp.163.com            # 邮箱所属服务器
    username: test8y5Wr@163.com   # 邮箱
    password: ZQCVOJLAPZEGEUZO    # 邮箱 smtp 授权码, 或邮箱密码(取决于邮箱种类)

  # JPA
  jpa:
    show-sql: true        # log 中打印 sql 语句, 便于排查错误
    open-in-view: false   # true = 保持数据库连接直至 controller 执行完

  task:
    # 线程池
    execution:
      pool:
        max-size: 16
        core-size: 16
        keep-alive: 10s
        queue-capacity: 100
        allow-core-thread-timeout: true
      # 线程名称前缀
      thread-name-prefix: async-task-

    # 定时任务
    scheduling:
      pool:
        size: 10

  # Elasticsearch
  elasticsearch:
    uris: http://localhost:9200
    socket-timeout: 60000
    connection-timeout: 60000
    password:

  # Kafka
  kafka:
    bootstrap-servers: localhost:9092
    template:
      default-topic: demo-topic
    consumer:
      group-id: demo-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 没有 offset 时配置 offset 的规则
      auto-offset-reset: earliest
      # 是否允许自动提交
      enable-auto-commit: false
      # 拉取数据时, 每批次最大数据量
      max-poll-records: 1000
      fetch-max-wait: 3s
      properties:
        isolation.level: read_committed
    listener:
      type: batch
      # 提交模式
      ack-mode: manual_immediate
      idle-event-interval: 10s
      concurrency: 4
      missing-topics-fatal: false
    producer:
      # 消息处理成功的条件: 0 不返回, 1 leader 收到返回成功, all/-1 全员收到返回成功
      acks: 1

  # Neo4j
  neo4j:
    uri: bolt://localhost:7687
    authentication:
      username: neo4j
      password: RVsdbgjs~4921

  # Redis
  redis:
    host: localhost
    port: 6379
    password: "xembec-1rasDi-paztoq"
    timeout: 10s  # 超时(时间 + 单位)
    lettuce:
      pool:
        max-active: 8
        # 需要时间单位
        max-wait: -1s
        max-idle: 8
        min-idle: 0

  # Swagger
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher

  # Thymeleaf
  thymeleaf:
    check-template-location: false

# 日志
logging:
  level:
    ROOT: info  # 最低展示级别 (error > warn > info > debug)
  pattern:
    file: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %highlight(%-5level) %green(%logger{50}).%M-%L - %msg %n'
    console: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %highlight(%-5level) %green(%logger{50}).%M-%L - %msg %n'
  logback:
    rolling policy:
      max-history: 10 # 最大保留时长(天)
      max-file-size: 100MB
  file:
    path: "logs"